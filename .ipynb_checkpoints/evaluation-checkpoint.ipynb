{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n number of subsequences of a patient's notes\n",
    "# c is scaling factor and controls influence of number of subsequences \n",
    "# use c= 2\n",
    "# pmax is max probability of readmission\n",
    "# pmean is mean probability of readmission\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')\n",
    "#tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(examples):\n",
    "     return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"../../models/orig_lr4e-5/checkpoint-12000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training model on tokenized and split data\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, labels):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val) for key, val in self.inputs[idx].items() if key != 'text'}\n",
    "        item['labels'] = torch.tensor(int(self.labels[idx]['text']))\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(test_dataset):\n",
    "    # generates prediction from model\n",
    "    train_pred = trainer.predict(test_dataset)\n",
    "    pred = train_pred.predictions\n",
    "    \n",
    "    # softmax each row so each row sums to 1\n",
    "    prob = softmax(pred, axis = 1)\n",
    "    \n",
    "    # find the mean probability of readmission\n",
    "    meanprob = np.mean(prob,axis=0)[1]\n",
    "    \n",
    "    # find the max probability of readmission\n",
    "    maxprob = np.amax(prob,axis=0)[1]\n",
    "    \n",
    "    n = pred.shape[0]\n",
    "    \n",
    "    # return mean, max, shape\n",
    "    return meanprob, maxprob, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(patientID):\n",
    "    # loading features and labels per patient\n",
    "    input_dataset = load_dataset('text', data_files={'test': '../../data/processPatient/'+patientID})\n",
    "    label_dataset = load_dataset('text', data_files={'test': '../../data/labels/'+patientID})\n",
    "    \n",
    "    # applying encoding function to dataset\n",
    "    input_dataset = input_dataset.map(encode, batched=True)\n",
    "    \n",
    "    # setting dataset to testing dataset\n",
    "    test_dataset = Dataset(input_dataset['test'], label_dataset['test'])\n",
    "    \n",
    "    return test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating readmit probability on per patient basis\n",
    "def readmit_probability(maxprob,meanprob,n):\n",
    "    # c accounts for patients with many notes\n",
    "    c=2\n",
    "    # weight as n/c\n",
    "    scaling = n/c\n",
    "    denominator = 1+scaling\n",
    "    numerator = maxprob + (meanprob * scaling)\n",
    "    \n",
    "    probability = numerator/denominator\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, roc_curve, auc, RocCurveDisplay, average_precision_score\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "# generating numpy array of all the real labels\n",
    "def patient_labels(patients):\n",
    "    labels = []\n",
    "    for i in range(len(patients)):\n",
    "        # taking label per patient\n",
    "        with open('../../data/labels/'+ patients[i], 'r') as f:\n",
    "            text = f.readline().strip()\n",
    "            if text == '1':\n",
    "                labels.append(1)\n",
    "            elif text == '0':\n",
    "                labels.append(0)\n",
    "    \n",
    "    label_array = np.asarray(labels)\n",
    "            \n",
    "    return label_array\n",
    "\n",
    "# take in probabilities per patient array and threshold\n",
    "# turn into list of labels of 0 or 1\n",
    "def convert_probability(pred, threshold):\n",
    "    labels= []\n",
    "    for val in pred:\n",
    "        if val>threshold:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "            \n",
    "    labels_array = np.asarray(labels)        \n",
    "    return labels_array\n",
    "\n",
    "# computing accuracy, f1, precision, recall, auroc\n",
    "# parameters are the arrays of predicted labels, real labels, and predicted probabilities\n",
    "def compute_metrics(pred_label, real_label, readmit_prob):\n",
    "    labels = real_label\n",
    "    preds = pred_label\n",
    "    predictions = readmit_prob\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    roc = roc_auc_score(labels, predictions)\n",
    "    fpr, tpr, thresholds = roc_curve(labels,predictions)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,)\n",
    "    display.plot()\n",
    "    prc = average_precision_score(labels, predictions)\n",
    "    \n",
    "    #precision, recall, _ = precision_recall_curve(labels, predictions)\n",
    "    #disp = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
    "    #disp.plot() \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        #'precision': precision,\n",
    "        #'recall': recall,\n",
    "        'auroc': roc,\n",
    "        #'auroc_display' : display,\n",
    "        'auprc': prc,\n",
    "        #'auprc_display' : disp,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/splits/valid_list','r') as f:\n",
    "    lines = f.read().splitlines()\n",
    "    set_valid = set(lines)\n",
    "valid_list = list(set_valid)\n",
    "\n",
    "with open('../../data/splits/test_list','r') as f:\n",
    "    lines = f.read().splitlines()\n",
    "    set_test = set(lines)\n",
    "test_list = list(set_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in list of patients from either valid split or test split\n",
    "# lists are valid_list or test_list\n",
    "def evaluate(split):\n",
    "    # empty list of scalable readmission prediction probabilities\n",
    "    patient_prob = []\n",
    "    \n",
    "    # load valid list for testing\n",
    "    for i in range(len(split)):\n",
    "        # load the patient datset\n",
    "        test_dataset = prepare_data(split[i])\n",
    "\n",
    "        # find the max and mean probability of readmission\n",
    "        mean, maximum, n = probability(test_dataset)\n",
    "\n",
    "        # calculate readmission probability per patient\n",
    "        readmit = readmit_probability(mean,maximum,n)\n",
    "\n",
    "        # add probabilities into list of all patient probabilities\n",
    "        patient_prob.append(readmit)\n",
    "        print(i)\n",
    "    \n",
    "    return patient_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset text (/home/ubuntu/.cache/huggingface/datasets/text/default-3e19ec7f7f2644f2/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab)\n",
      "Using custom data configuration default\n",
      "Reusing dataset text (/home/ubuntu/.cache/huggingface/datasets/text/default-34f5df87db561b03/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab)\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-3e19ec7f7f2644f2/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab/cache-19a967c3df8a5d42.arrow\n",
      "Using custom data configuration default\n",
      "Reusing dataset text (/home/ubuntu/.cache/huggingface/datasets/text/default-0bf049cc091870e0/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset text (/home/ubuntu/.cache/huggingface/datasets/text/default-a441e02143a1abca/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab)\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-0bf049cc091870e0/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab/cache-616bbec74ed4ee7c.arrow\n",
      "Using custom data configuration default\n",
      "Reusing dataset text (/home/ubuntu/.cache/huggingface/datasets/text/default-23a84bc2cc97cf4b/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab)\n",
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset text (/home/ubuntu/.cache/huggingface/datasets/text/default-acf0c736ef08f158/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab)\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-23a84bc2cc97cf4b/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab/cache-ed2798692e7b3b2a.arrow\n",
      "Using custom data configuration default\n",
      "Reusing dataset text (/home/ubuntu/.cache/huggingface/datasets/text/default-66c402bcb3f582e6/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab)\n",
      "Using custom data configuration default\n",
      "Reusing dataset text (/home/ubuntu/.cache/huggingface/datasets/text/default-e39417a9a212b3b6/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-66c402bcb3f582e6/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab/cache-bcfa9de01cf3890b.arrow\n",
      "Using custom data configuration default\n",
      "Reusing dataset text (/home/ubuntu/.cache/huggingface/datasets/text/default-00a5a346a53920a8/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab)\n",
      "Using custom data configuration default\n",
      "Reusing dataset text (/home/ubuntu/.cache/huggingface/datasets/text/default-7fb1e5d2e54bef16/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab)\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-00a5a346a53920a8/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab/cache-50f7250a16eb7cba.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-bdad332f4ba0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# generating patient probability from model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# pass in either valid_list or test_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpatient_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# generating actual labels of patients for valid list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-85318cdb3d22>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(split)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# find the max and mean probability of readmission\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# calculate readmission probability per patient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-32b139964f81>\u001b[0m in \u001b[0;36mprobability\u001b[0;34m(test_dataset)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# generates prediction from model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_test_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m         return self.prediction_loop(\n\u001b[0m\u001b[1;32m   1381\u001b[0m             \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m                 \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   1546\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1547\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1548\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1549\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhas_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m         distilbert_output = self.distilbert(\n\u001b[0m\u001b[1;32m    617\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m         return self.transformer(\n\u001b[0m\u001b[1;32m    482\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m             layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    309\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;31m# Feed Forward Network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffn_output\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msa_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_chunking_to_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mff_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   1782\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1784\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mff_chunk\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# generating patient probability from model\n",
    "# pass in either valid_list or test_list\n",
    "patient_prob = evaluate(valid_list[:15])\n",
    "\n",
    "# generating actual labels of patients for valid list\n",
    "# pass in either valid_list or test_list\n",
    "real_labels = patient_labels(valid_list[:15])\n",
    "\n",
    "# turn predicted probability list into 1d numpy array\n",
    "pred_prob = np.asarray(patient_prob)\n",
    "\n",
    "# generate label array from probability list and threshold\n",
    "# if probability over a certain threshold, generate a readmit label of 1\n",
    "# otherwise, readmit = 0\n",
    "pred_labels = convert_probability(pred_prob,0.1)\n",
    "\n",
    "print(real_labels)\n",
    "print(pred_prob)\n",
    "print(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9652173913043478,\n",
       " 'f1': 0.888888888888889,\n",
       " 'auroc': 0.9672245212877885,\n",
       " 'auprc': 0.9291009498125172}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# computing the metrics \n",
    "compute_metrics(s3pred_labels, s3real_labels,s3pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1real_labels = np.load('../../models/ssmba_0.1/real_labels.npz')\n",
    "s1pred_prob = np.load('../../models/ssmba_0.1/pred_prob.npz')\n",
    "s1pred_labels = convert_probability(s1pred_prob, 0.55)\n",
    "\n",
    "s2real_labels = np.load('../../models/ssmba_0.2/real_labels.npz')\n",
    "s2pred_prob = np.load('../../models/ssmba_0.2/pred_prob.npz')\n",
    "s2pred_labels = convert_probability(s2pred_prob, 0.8)\n",
    "\n",
    "s3real_labels = np.load('../../models/ssmba_0.3/real_labels.npz')\n",
    "s3pred_prob = np.load('../../models/ssmba_0.3/pred_prob.npz')\n",
    "s3pred_labels = convert_probability(s3pred_prob, 0.85)\n",
    "\n",
    "s4real_labels = np.load('../../models/ssmba_0.4/real_labels.npz')\n",
    "s4pred_prob = np.load('../../models/ssmba_0.4/pred_prob.npz')\n",
    "s4pred_labels = convert_probability(s4pred_prob, 0.85)\n",
    "\n",
    "real_labels = np.load('../../models/orig_lr4e-5/real_labels.npz')\n",
    "pred_prob = np.load('../../models/orig_lr4e-5/pred_prob.npz')\n",
    "pred_labels = convert_probability(pred_prob, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8500000000000002\n"
     ]
    }
   ],
   "source": [
    "test = 0.0\n",
    "threshold = 0.05\n",
    "optimize = 0.0\n",
    "while threshold < 1.0:\n",
    "    s3pred_labels = convert_probability(s3pred_prob, threshold)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(s3real_labels, s3pred_labels, average='binary')\n",
    "    if f1 > test:\n",
    "        test = f1\n",
    "        optimize = threshold\n",
    "    threshold += 0.05\n",
    "print(optimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n"
     ]
    }
   ],
   "source": [
    "test = 0.0\n",
    "threshold = 0.05\n",
    "optimize = 0.0\n",
    "while threshold < 1.0:\n",
    "    s1pred_labels = convert_probability(s1pred_prob, threshold)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(s1real_labels, s1pred_labels, average='binary')\n",
    "    if precision > 0.8:\n",
    "        optimize = threshold\n",
    "        \n",
    "    threshold += 0.05\n",
    "print(optimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset text (/home/ubuntu/.cache/huggingface/datasets/text/default-a1ba682b66c55cb5/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab)\n",
      "Using custom data configuration default\n",
      "Reusing dataset text (/home/ubuntu/.cache/huggingface/datasets/text/default-bf9a0a18d9225359/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab)\n",
      "Loading cached processed dataset at /home/ubuntu/.cache/huggingface/datasets/text/default-a1ba682b66c55cb5/0.0.0/daf90a707a433ac193b369c8cc1772139bb6cca21a9c7fe83bdd16aad9b9b6ab/cache-c52975535d677fb8.arrow\n"
     ]
    }
   ],
   "source": [
    "# load the patient datset\n",
    "test1_dataset = prepare_data(valid_list[10])\n",
    "\n",
    "# find the max and mean probability of readmission\n",
    "mean1, maximum1, n1 = probability(test1_dataset)\n",
    "\n",
    "# calculate readmission probability per patient\n",
    "readmit1 = readmit_probability(mean1,maximum1,n1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
